{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 32-bit",
   "display_name": "Python 3.8.5 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "7a542ca580817fc4dd55327026e074e2fa0cd470fc5dee9350c2d8b13822db8d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import toml\n",
    "from os.path import join\n",
    "import glob\n",
    "import pcoss_scheduler_pkg.problem_input as cpi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_max_size = 64\n",
    "machines_max_size = 64\n",
    "# dir_path = r'../../data/auto/'\n",
    "dir_path = r'C:\\git\\mgr\\data\\auto'\n",
    "# base_url = r'https://localhost:5001/Operations'\n",
    "# base_url = r'https://localhost:44320/Operations'\n",
    "base_url = r'https://rapid-sphinx-291111.ey.r.appspot.com/Operations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sizes = lambda size: [int(2**i) for i in range(1, int(np.log2(size)+1))]\n",
    "job_sizes = sizes(jobs_max_size)\n",
    "machine_sizes = sizes(machines_max_size)\n",
    "conflicting_machines = {\n",
    "    1: [],\n",
    "    2: [],\n",
    "    4: [(1, 2)],\n",
    "    8: [(1, 2), (5, 7)],\n",
    "    16: [(1, 2), (5, 7), (9, 10), (13, 14)],\n",
    "    32: [(1, 2), (5, 7), (9, 10), (13, 14), (15, 16), (17, 18), (20, 25), (27, 30)],\n",
    "    64: [(1, 2), (5, 7), (9, 10), (13, 14), (15, 16), (17, 18), (20, 25), (27, 30), (33, 35), (34, 36), (39, 44), (45, 46), (48, 55), (57, 58), (60, 61), (62, 63)]\n",
    "}\n",
    "\n",
    "for jobs_cnt in job_sizes:\n",
    "    for machines_cnt in machine_sizes:\n",
    "        problem_name = f'{jobs_cnt}j{machines_cnt}m0'\n",
    "        \n",
    "        data_file_name = f'{problem_name}_data'\n",
    "        pt_file_name = f'{problem_name}_pt'\n",
    "\n",
    "        data_csv_file_path = f'{join(dir_path, data_file_name)}.csv'\n",
    "        pt_csv_file_path = f'{join(dir_path, pt_file_name)}.csv'\n",
    "\n",
    "        np.savetxt(\n",
    "            data_csv_file_path,\n",
    "            np.random.rand(jobs_cnt, machines_cnt),\n",
    "            fmt='%.2f',\n",
    "            delimiter=',')\n",
    "\n",
    "        np.savetxt(\n",
    "            pt_csv_file_path,\n",
    "            np.random.rand(jobs_cnt, machines_cnt) * 10_000,\n",
    "            fmt='%.2f',\n",
    "            delimiter=',')\n",
    "\n",
    "        toml_dict = {\n",
    "            'title': problem_name,\n",
    "            'info': f'{jobs_cnt} jobs {machines_cnt} machines example 0',\n",
    "            'files':\n",
    "            {\n",
    "                'data': data_csv_file_path,\n",
    "                'processing_times': pt_csv_file_path\n",
    "            },\n",
    "            'problem_data':\n",
    "            {\n",
    "                'index_cols': [],\n",
    "                'grouping_cols': [],\n",
    "                'conflicting_machines': conflicting_machines[machines_cnt],\n",
    "                'base_url': base_url\n",
    "            },\n",
    "            'algorithm_config':\n",
    "            {\n",
    "                'algorithm_name': 'insertion_beam',\n",
    "                'objective': 'cmax',\n",
    "                'beam_width': 5\n",
    "            },\n",
    "            'display_config':\n",
    "            {\n",
    "                'print_responses': True,\n",
    "                'print_method_times': False,\n",
    "                'show_conflict_graph': True,\n",
    "                'show_result_schedule_graph': True,\n",
    "                'show_gantt_plot': True\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(join(dir_path, f'{problem_name}.toml'), 'w') as f:\n",
    "            f.write(toml.dumps(toml_dict).replace(',]', ' ]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(r'../../data/auto/*.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_times_df = (\n",
    "    pd.read_csv('testing_times.csv', usecols=['0','1','2'])\n",
    "    .rename(columns={'0': 'file', '1': 'prep_time', '2': 'max_end_time'})\n",
    ")\n",
    "op_times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_primitive_time(row, conflicts):\n",
    "    l = []\n",
    "    for c1, c2 in conflicts:\n",
    "        l.append(row[c1] + row[c2])\n",
    "    l.append(max(row))\n",
    "    return max(l)\n",
    "\n",
    "op_times_df['jobs'] = op_times_df['file'].str.extract(r'^[^\\d]+(\\d+)j.*$').astype(np.int)\n",
    "op_times_df['machines'] = op_times_df['file'].str.extract(r'^[^\\d]+\\d+j(\\d+)m.*$').astype(np.int)\n",
    "op_times_df['cells'] = op_times_df.jobs * op_times_df.machines\n",
    "op_times_df['primitive_time'] = 0\n",
    "op_times_df['seq_op_time'] = 0\n",
    "\n",
    "for idx, o in op_times_df.iterrows():\n",
    "    pf = o.file\n",
    "    # print(pf)\n",
    "    pi = cpi.ProblemInput.from_toml(pf)\n",
    "    op_times_df.loc[idx, 'primitive_time'] = sum(pi.processing_times.apply(lambda r: calc_primitive_time(r, pi.conflicting_machines_list), axis=1))\n",
    "    op_times_df.loc[idx, 'seq_op_time'] = sum(pi.processing_times.apply(lambda r: r.sum(), axis=1))\n",
    "\n",
    "op_times_df['time_ratio'] = op_times_df.max_end_time / op_times_df.primitive_time\n",
    "op_times_df['time_ratio_2'] = op_times_df.max_end_time / op_times_df.seq_op_time\n",
    "op_times_df.sort_values('cells')\n",
    "\n",
    "g = sns.relplot(x=\"cells\", y=\"time_ratio\", data=op_times_df, kind=\"line\",)\n",
    "g = sns.relplot(x=\"cells\", y=\"time_ratio_2\", data=op_times_df, kind=\"line\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.relplot(x=\"machines\", y=\"prep_time\", data=op_times_df[op_times_df.jobs==128], kind=\"line\",)\n",
    "g = sns.relplot(x=\"machines\", y=\"prep_time\", data=op_times_df[op_times_df.jobs==32], kind=\"line\",)\n",
    "\n",
    "# g.fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(x=\"jobs\", y=\"prep_time\", data=op_times_df[op_times_df.machines==16], kind=\"line\",)\n",
    "# g.fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from random import random\n",
    "\n",
    "def f(x, a, b, c):\n",
    "    return b * (x**a) + c\n",
    "\n",
    "op_times_df\n",
    "\n",
    "p1, p2 = curve_fit(f, xdata=op_times_df[op_times_df.machines==16].jobs, ydata=op_times_df[op_times_df.machines==16].prep_time)\n",
    "\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}